{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I want initially is to use the whole 3000 stocks.\n",
    "However due to the capacity of my laptop, now, I can only use one of them to form a baby-version model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the tradeoff of computing capacity and performance, I focus on two industries: Finance and Real Estate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance=pd.read_excel('e:/data/finance.xlsx')\n",
    "real_estate=pd.read_excel('e:/data/real_estate.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=finance['finance']\n",
    "rea=real_estate['real_estate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the most resent 10 years' data to build my model.\n",
    "And split the train and test set by proportion of 7:3, which means data from 2006-09-01 to 2013-09-02 is the training set, while data from 2013-09-02 to 2016-09-01 is the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_name=[]\n",
    "for i in range(7):\n",
    "    for j in ['clsPrc','highPrc','lowPrc','openPrc','clsPrc_lastday','diff',\n",
    "              'return', 'turnover_rate','volumn','turnover_value','total_market_value','current_market_value']:\n",
    "        column_name.append(str(j)+'_lag'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "database={}\n",
    "trainset={}\n",
    "testset={}\n",
    "for i in fin:\n",
    "    \n",
    "    #import my data\n",
    "    \n",
    "    name=str('0')+str(i)\n",
    "    if os.path.isfile('e:/data/'+str(name)+'.csv'):\n",
    "        data=pd.read_csv('e:/data/'+str(name)+'.csv',encoding='gb2312')\n",
    "        data.columns=['date','code','name','clsPrc','highPrc','lowPrc','openPrc','clsPrc_lastday','diff',\n",
    "              'return', 'turnover_rate','volumn','turnover_value','total_market_value','current_market_value','hh']\n",
    "        data=data.drop(['hh'],axis=1)\n",
    "\n",
    "        #select the data\n",
    "\n",
    "        if sum(data['date']=='2006-09-01')==1 and sum(data['date']=='2013-09-02')==1:\n",
    "\n",
    "            #add some features\n",
    "\n",
    "            for lag in range(7):     ## [1,2,3,4,5,6,7,8,9,10] will be better\n",
    "                for col_name in ['clsPrc','highPrc','lowPrc','openPrc','clsPrc_lastday','diff', 'return', 'turnover_rate','volumn','turnover_value','total_market_value','current_market_value']:\n",
    "                    data[str(col_name)+'_lag'+str(lag+1)]=data[str(col_name)].shift(-lag-1)\n",
    "\n",
    "\n",
    "                    #split the training set and the test set\n",
    "\n",
    "            cutoff1=(data[data['date']=='2006-09-01'].index)\n",
    "            cutoff2=(data[data['date']=='2013-09-02'].index)\n",
    "            data=data[data.index<cutoff1[0]]\n",
    "            train=data[data.index>cutoff2[0]]\n",
    "            test =data[data.index<cutoff2[0]]\n",
    "            database.update({str(name):data})\n",
    "            trainset.update({'train_'+str(name):train})\n",
    "            testset.update({'test_'+str(name):test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rea:\n",
    "    \n",
    "    #import my data\n",
    "    \n",
    "    name=str('0')+str(i)\n",
    "    if os.path.isfile('e:/data/'+str(name)+'.csv'):\n",
    "        data=pd.read_csv('e:/data/'+str(name)+'.csv',encoding='gb2312')\n",
    "        data.columns=['date','code','name','clsPrc','highPrc','lowPrc','openPrc','clsPrc_lastday','diff',\n",
    "              'return', 'turnover_rate','volumn','turnover_value','total_market_value','current_market_value','hh']\n",
    "        data=data.drop(['hh'],axis=1)\n",
    "\n",
    "        #select the data\n",
    "\n",
    "        if sum(data['date']=='2006-09-01')==1 and sum(data['date']=='2013-09-02')==1:\n",
    "\n",
    "            #add some features\n",
    "\n",
    "            for lag in range(7):     ## [1,2,3,4,5,6,7,8,9,10] will be better\n",
    "                for col_name in ['clsPrc','highPrc','lowPrc','openPrc','clsPrc_lastday','diff', 'return', 'turnover_rate','volumn','turnover_value','total_market_value','current_market_value']:\n",
    "                    data[str(col_name)+'_lag'+str(lag+1)]=data[str(col_name)].shift(-lag-1)\n",
    "\n",
    "\n",
    "                    #split the training set and the test set\n",
    "\n",
    "            cutoff1=(data[data['date']=='2006-09-01'].index)\n",
    "            cutoff2=(data[data['date']=='2013-09-02'].index)\n",
    "            data=data[data.index<cutoff1[0]]\n",
    "            train=data[data.index>cutoff2[0]]\n",
    "            test =data[data.index<cutoff2[0]]\n",
    "            database.update({str(name):data})\n",
    "            trainset.update({'train_'+str(name):train})\n",
    "            testset.update({'test_'+str(name):test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2862: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "trainsetX={}\n",
    "trainsety={}\n",
    "testsetX={}\n",
    "testsety={}\n",
    "\n",
    "for code in database.keys():\n",
    "    name=code\n",
    "    train=trainset['train_'+str(name)]\n",
    "    test=testset['test_'+str(name)]\n",
    "    for i in column_name:\n",
    "    \n",
    "        train[i]=pd.to_numeric(train[i].values,errors='coerce')\n",
    "        where_are_NaNs = np.isnan(train[i])\n",
    "        train[str(i)][where_are_NaNs] = 0\n",
    "\n",
    "        test[i]=pd.to_numeric(test[i].values,errors='coerce')\n",
    "        where_are_NaNs = np.isnan(test[i])\n",
    "        test[i][where_are_NaNs] = 0\n",
    "\n",
    "    X_train=train[column_name]\n",
    "    y_train=pd.to_numeric(train['diff'].values,errors='coerce')\n",
    "\n",
    "    X_test=test[column_name]\n",
    "    y_test=pd.to_numeric(test['diff'].values,errors='coerce')\n",
    "\n",
    "    where_are_NaNs1 = np.isnan(y_train)\n",
    "    y_train[where_are_NaNs1] = 0\n",
    "    where_are_NaNs2 = np.isnan(y_test)\n",
    "    y_test[where_are_NaNs2] = 0\n",
    "    y_train=(y_train>0)*1\n",
    "    y_test=(y_test>0)*1\n",
    "    \n",
    "    trainsetX.update({'trainX_'+str(name):X_train})\n",
    "    trainsety.update({'trainy_'+str(name):y_train})\n",
    "    testsetX.update({'testX_'+str(name):X_test})\n",
    "    testsety.update({'testy_'+str(name):y_test})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 84 to array axis with dimension 1699",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    376\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (1699,84) into shape (1699)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-89f2414f7630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainsetX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainsetX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trainX_0600000'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clsPrc_lag1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    273\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    274\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   5499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5500\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5501\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5503\u001b[0m     \u001b[1;31m# from BlockManager perspective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m   5810\u001b[0m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5811\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[1;32m-> 5812\u001b[1;33m                                 raise_cast_failure=False)\n\u001b[0m\u001b[0;32m   5813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5814\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m   3027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3029\u001b[1;33m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3031\u001b[0m     \u001b[1;31m# This is to prevent mixed-type Series getting all casted to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# we have a list-of-list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot copy sequence with size 84 to array axis with dimension 1699"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(trainsetX,index=range(len(trainsetX['trainX_0600000']['clsPrc_lag1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0600291\n",
      "0.568894952251\n",
      "0600318\n",
      "0.680763983629\n",
      "0600816\n",
      "0.470668485675\n",
      "0600015\n",
      "0.496589358799\n",
      "0600155\n",
      "0.649386084584\n",
      "0600705\n",
      "0.429740791269\n",
      "0600643\n",
      "0.429740791269\n",
      "0600000\n",
      "0.481582537517\n",
      "0600061\n",
      "0.555252387449\n",
      "0600695\n",
      "0.455661664393\n",
      "0600837\n",
      "0.487039563438\n",
      "0600016\n",
      "0.534788540246\n",
      "0600369\n",
      "0.472032742156\n",
      "0600036\n",
      "0.537517053206\n",
      "0600030\n",
      "0.485675306958\n",
      "0600109\n",
      "0.502732240437\n",
      "0600621\n",
      "0.464480874317\n",
      "0600390\n",
      "0.443383356071\n",
      "0600599\n",
      "0.424283765348\n",
      "0601988\n",
      "0.568894952251\n",
      "0600162\n",
      "0.457025920873\n",
      "0600067\n",
      "0.49795361528\n",
      "0600807\n",
      "0.444747612551\n",
      "0600240\n",
      "0.537517053206\n",
      "0600159\n",
      "0.458390177353\n",
      "0600223\n",
      "0.485675306958\n",
      "0600533\n",
      "0.437158469945\n",
      "0600064\n",
      "0.478854024557\n",
      "0600736\n",
      "0.442019099591\n",
      "0600510\n",
      "0.49931787176\n",
      "0600053\n",
      "0.321038251366\n",
      "0600077\n",
      "0.487039563438\n",
      "0600716\n",
      "0.493860845839\n",
      "0600173\n",
      "0.442019099591\n",
      "0600340\n",
      "0.533424283765\n",
      "0600325\n",
      "0.521145975443\n",
      "0600503\n",
      "0.463847203274\n",
      "0600724\n",
      "0.487039563438\n",
      "0600158\n",
      "0.529331514325\n",
      "0600322\n",
      "0.459754433834\n",
      "0600649\n",
      "0.62346521146\n",
      "0600638\n",
      "0.507503410641\n",
      "0600604\n",
      "0.532060027285\n",
      "0600732\n",
      "0.380348652932\n",
      "0600823\n",
      "0.514324693042\n",
      "0600665\n",
      "0.514324693042\n",
      "0600748\n",
      "0.508867667121\n",
      "0600696\n",
      "0.556616643929\n",
      "0600185\n",
      "0.519781718963\n",
      "0600094\n",
      "0.496589358799\n",
      "0600225\n",
      "0.506139154161\n",
      "0600622\n",
      "0.521857923497\n",
      "0600708\n",
      "0.540245566166\n",
      "0600730\n",
      "0.592087312415\n",
      "0600817\n",
      "0.259208731241\n",
      "0600641\n",
      "0.433833560709\n",
      "0600606\n",
      "0.56207366985\n",
      "0600675\n",
      "0.489768076398\n",
      "0600663\n",
      "0.455661664393\n",
      "0600773\n",
      "0.491803278689\n",
      "0600376\n",
      "0.504774897681\n",
      "0600007\n",
      "0.452933151432\n",
      "0600246\n",
      "0.361527967258\n",
      "0600266\n",
      "0.508867667121\n",
      "0600657\n",
      "0.512960436562\n",
      "0600658\n",
      "0.487039563438\n",
      "0600683\n",
      "0.50204638472\n",
      "0600052\n",
      "0.465211459754\n",
      "0600208\n",
      "0.524590163934\n",
      "0600239\n",
      "0.50204638472\n",
      "0600565\n",
      "0.536152796726\n",
      "0600177\n",
      "0.514324693042\n",
      "0600684\n",
      "0.49043715847\n",
      "0600383\n",
      "0.504774897681\n",
      "0600393\n",
      "0.457650273224\n",
      "0600733\n",
      "0.541609822647\n",
      "0600466\n",
      "0.514324693042\n",
      "0600791\n",
      "0.507503410641\n",
      "0600515\n",
      "0.556616643929\n",
      "0600215\n",
      "0.481582537517\n",
      "0600890\n",
      "0.646657571623\n",
      "0600555\n",
      "0.450204638472\n",
      "0600048\n",
      "0.443383356071\n",
      "0600848\n",
      "0.395634379263\n",
      "0600639\n",
      "0.477489768076\n",
      "0600743\n",
      "0.480218281037\n"
     ]
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for code in database.keys():\n",
    "    name=code\n",
    "    X_train=trainsetX['trainX_'+str(name)]\n",
    "    y_train=trainsety['trainy_'+str(name)]\n",
    "    X_test=testsetX['testX_'+str(name)]\n",
    "    y_test=testsety['testy_'+str(name)]\n",
    "\n",
    "    # 2. instantiate\n",
    "    mlp = MLPClassifier()\n",
    "\n",
    "    # 3. train\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # 4. predict\n",
    "    p = mlp.predict(X_test)\n",
    "\n",
    "    # 5. evaluate\n",
    "    print(code)\n",
    "    print(metrics.accuracy_score(p, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
